{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, name):\n",
    "    with open('../data/out.{}.json'.format(name), 'w') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations = pd.read_csv('../data/languages_coordinates.csv')\n",
    "lang_locations.drop(['glottocode', 'macroarea'], 1, inplace=True)\n",
    "lang_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = pd.read_csv('../data/etymwn.tsv', sep='\\t', header=None)\n",
    "relations.columns = ['src', 'rel', 'to']\n",
    "relations = relations[\n",
    "    ~relations.src.apply(lambda x: len(x.split(' ')) > 4) &\n",
    "    ~relations.to.apply(lambda x: len(x.split(' ')) > 4) &\n",
    "    ~relations.src.apply(lambda x: len(x.split(':')) > 2) &\n",
    "    ~relations.to.apply(lambda x: len(x.split(':')) > 2) &\n",
    "    ~relations.src.str.contains('-') & \n",
    "    ~relations.src.str.contains('\\[') & \n",
    "    ~relations.to.str.contains('-') &\n",
    "    ~relations.to.str.contains('\\[') &\n",
    "    ~relations.rel.isin(['rel:is_derived_from', 'rel:etymologically_related', 'derived'])\n",
    "]\n",
    "relations = relations.assign(\n",
    "    src_lang=relations.src.apply(lambda x: x.split(':')[0].strip()),\n",
    "    src_word=relations.src.apply(lambda x: x.split(':')[1].strip().lower()),\n",
    "    to_lang=relations.to.apply(lambda x: x.split(':')[0].strip()),\n",
    "    to_word=relations.to.apply(lambda x: x.split(':')[1].strip().lower()),\n",
    ")\n",
    "relations = relations[relations.to_word != relations.src_word]\n",
    "relations.drop_duplicates(inplace=True)\n",
    "relations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_per_lang = relations.groupby(relations.to_lang).count().to_word\n",
    "words_per_lang.sort_values(ascending=False).plot(logy=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word = 20\n",
    "langs = pd.Series(words_per_lang[words_per_lang > min_word].index)\n",
    "langs.sort_values()\n",
    "langs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations[lang_locations.isocode.isin(langs)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrolangs = pd.read_csv('../data/macrolanguages.tsv', sep='\\t')\n",
    "macrolangs.drop(['I_Status'], 1, inplace=True)\n",
    "macrolangs = macrolangs[~macrolangs.I_Id.isin(langs) & macrolangs.I_Id.isin(lang_locations.isocode)]\n",
    "macrolangs = dict(macrolangs.groupby(macrolangs.M_Id).first().reset_index().values)\n",
    "len(macrolangs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_lang = ~langs.isin(lang_locations.isocode)\n",
    "langs[unknown_lang] = langs[unknown_lang].apply(macrolangs.get)\n",
    "langs = langs[langs.values != None]\n",
    "langs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations_patch = np.array([\n",
    "    [34.5, 41],\n",
    "    [37.1, -3.5],\n",
    "    [51, 0],\n",
    "    [40.3, 45],\n",
    "    [28, 84.5],\n",
    "    [52, 5],\n",
    "    [52, -1],\n",
    "    [48, 2],\n",
    "    [48.649, 11.4676],\n",
    "    [48.649, 13.4676],\n",
    "    [59.92, 10.71],\n",
    "    [52, 5],\n",
    "    [52, 0],\n",
    "    [47, 2],\n",
    "    [53.3, 6.3],\n",
    "    [47.649, 12.4676],\n",
    "    [53.2, -7.5],\n",
    "    [55.7, 12],\n",
    "    [32, 50],\n",
    "    [44.3, 4],\n",
    "    [56, 37],\n",
    "    [51.152, 12.692],\n",
    "    [40.4414, -1.11788],\n",
    "    [39.8667, 32.8667],\n",
    "    [52, -4],\n",
    "    [32, 50],\n",
    "    [52, 14]\n",
    "])\n",
    "lang_locations_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations.loc[lang_locations.isocode.isin(langs) & lang_locations.latitude.isnull(), ['latitude', 'longitude']] = lang_locations_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations[lang_locations.isocode.isin(langs) & lang_locations.latitude.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_locations = lang_locations[lang_locations.isocode.isin(langs)]\n",
    "lang_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = relations[relations.src_lang.isin(langs) & relations.to_lang.isin(langs)]\n",
    "relations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_rel = relations[relations.rel != 'rel:etymology']\n",
    "parents_rel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "words.update(relations.src_word)\n",
    "words.update(relations.to_word)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_per_lang = pd.DataFrame(dict(\n",
    "    word=np.r_[relations.src_word, relations.to_word],\n",
    "    lang=np.r_[relations.src_lang, relations.to_lang],\n",
    "))\n",
    "word_per_lang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_langs = dict(word_per_lang.groupby(word_per_lang.word).lang.apply(lambda x: list(np.unique(x))).reset_index().values)\n",
    "len(word_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(word_langs, 'word_langs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_per_lang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_cases = word_per_lang.groupby(word_per_lang.lang).word.apply(list)\n",
    "lang_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_count = word_per_lang.groupby(word_per_lang.lang).word.count()\n",
    "lang_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_len_means = lang_cases.apply(lambda w: float(np.mean([len(x) for x in w])))\n",
    "lang_len_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_len_percentiles = lang_cases.apply(lambda w: np.percentile([len(x) for x in w], [25, 50, 75]))\n",
    "lang_len_percentiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_len_std = lang_cases.apply(lambda w: float(np.std([len(x) for x in w])))\n",
    "lang_len_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_cases_letters = lang_cases.apply(lambda w: [x for xx in w for x in xx])\n",
    "lang_cases_letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_letters = lang_cases_letters.apply(lambda w: [(l, int(c)) for l, c in zip(*np.unique(w, return_counts=True))])\n",
    "lang_letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_stats = pd.DataFrame(dict(\n",
    "    count=lang_count,\n",
    "    mean=lang_len_means,\n",
    "    std=lang_len_std,\n",
    "    percentile25=lang_len_percentiles.apply(lambda x: float(x[0])),\n",
    "    percentile50=lang_len_percentiles.apply(lambda x: float(x[1])),\n",
    "    percentile75=lang_len_percentiles.apply(lambda x: float(x[2])),\n",
    "    histogram=lang_letters\n",
    "))\n",
    "lang_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_count = relations.groupby(relations.to_lang).to_word.count()\n",
    "src_to_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to = parents_rel.groupby([parents_rel.src_lang, parents_rel.to_lang]).count().rel\n",
    "src_to.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_to = {}\n",
    "\n",
    "for (src, to), count in src_to.items():\n",
    "    if src not in network_to:\n",
    "        network_to[src] = []\n",
    "        \n",
    "    ratio = count# / src_to_count.loc[to]\n",
    "    #assert ratio <= 1\n",
    "    network_to[src].append([to, ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_src_count = relations.groupby(relations.src_lang).src_word.count()\n",
    "to_src_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_src = parents_rel.groupby([parents_rel.to_lang, parents_rel.src_lang]).count().rel\n",
    "to_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_src.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_from = {}\n",
    "\n",
    "for (to, src), count in to_src.items():\n",
    "    if to not in network_from:\n",
    "        network_from[to] = []\n",
    "        \n",
    "    ratio = count# / to_src_count.loc[src]\n",
    "    #assert ratio <= 1\n",
    "    network_from[to].append([src, ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save({\n",
    "    'to': network_to,\n",
    "    'from': network_from,\n",
    "    'locations': lang_locations.set_index('isocode').to_dict('index'),\n",
    "    'stats': lang_stats.to_dict('index')\n",
    "}, 'lang_network')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pd.read_csv('../data/uwn.tsv', sep='\\t', header=None)\n",
    "mappings.columns = ['src', 'rel', 'to', 'weight']\n",
    "mappings = mappings[mappings.rel != 'rel:means']\n",
    "mappings = mappings.assign(\n",
    "    lang=mappings.to.apply(lambda x: x.split('/')[1].strip()),\n",
    "    word=mappings.to.apply(lambda x: x.split('/')[2].strip().lower()),\n",
    ")\n",
    "mappings = mappings[mappings.word.isin(words) & mappings.lang.isin(langs)]\n",
    "mappings.drop(['weight', 'rel'], axis=1, inplace=True)\n",
    "mappings.set_index('src', inplace=True)\n",
    "mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = mappings.groupby(mappings.index).apply(lambda x: list(x.lang.str.cat(':' + x.word)))\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanings = {}\n",
    "\n",
    "for _, cluster in tqdm(clusters.items()):\n",
    "        \n",
    "    for lang_word in cluster:\n",
    "        \n",
    "        if lang_word not in meanings:\n",
    "            meanings[lang_word] = set()\n",
    "            \n",
    "        meanings[lang_word].update(cluster)\n",
    "        meanings[lang_word].remove(lang_word)\n",
    "        \n",
    "for key, values in meanings.items():\n",
    "    meanings[key] = list(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(meanings, 'word_meanings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = pd.DataFrame(dict(\n",
    "     src=parents_rel.src_lang + ':' + parents_rel.src_word + ',',\n",
    "    to=parents_rel.to_lang + ':' + parents_rel.to_word,\n",
    ")).groupby('to').src.sum()\n",
    "parents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_map = dict(parents.apply(lambda x: x.split(',')[:-1]).reset_index().values)\n",
    "len(parents_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(parents_map, 'word_parents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = pd.DataFrame(dict(\n",
    "     src=parents_rel.src_lang + ':' + parents_rel.src_word,\n",
    "    to=parents_rel.to_lang + ':' + parents_rel.to_word + ',',\n",
    ")).groupby('src').to.sum()\n",
    "children.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_map = dict(children.apply(lambda x: x.split(',')[:-1]).reset_index().values)\n",
    "len(children_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(children_map, 'word_children')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurse(lang_word, mapping, seen=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "\n",
    "    if lang_word in seen:\n",
    "        return []\n",
    "    \n",
    "    seen.add(lang_word)\n",
    "    ps = mapping.get(lang_word, [])\n",
    "    return [(p, recurse(p, mapping, seen.copy())) for p in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurse('eng:dog', parents_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurse('eng:dog', children_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurse_unfold(lang_word, mapping):\n",
    "    \n",
    "    edges = []\n",
    "    depth = 0\n",
    "    \n",
    "    def edgify(lang_word, history=[], seen=None):\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "        \n",
    "        ps = mapping.get(lang_word, [])\n",
    "\n",
    "        if lang_word in seen:\n",
    "            edges.append(history)\n",
    "            return\n",
    "        \n",
    "        if not len(ps):\n",
    "            edges.append(history + [lang_word])\n",
    "            return\n",
    "\n",
    "        seen.add(lang_word)\n",
    "        [edgify(p, history + [lang_word], seen.copy()) for p in ps]\n",
    "\n",
    "    edgify(lang_word)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurse_unfold('eng:dog', parents_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurse_unfold('eng:dog', children_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_words = (parents_rel.src_lang + ':' + parents_rel.src_word).values\n",
    "lang_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_influences = {}\n",
    "\n",
    "for lang_word in tqdm(lang_words):\n",
    "    edges = recurse_unfold(lang_word, parents_map) + recurse_unfold(lang_word, children_map)\n",
    "    \n",
    "    for edge in edges:\n",
    "        lang = edge[0].split(':')[0]\n",
    "\n",
    "        if lang not in lang_influences:\n",
    "            lang_influences[lang] = []\n",
    "\n",
    "        lang_influences[lang].append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_influences_ord = { k: sorted(v, key=len, reverse=True) for k, v in tqdm(lang_influences.items()) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_samples = {}\n",
    "\n",
    "for lang in tqdm(langs):\n",
    "    if lang in lang_influences:\n",
    "        top_starters = [lang_word[0].split(':')[1] for lang_word in lang_influences_ord[lang]]\n",
    "\n",
    "        lang_samples[lang] = [top_starters[i] for i in sorted(np.unique(top_starters, return_index=True)[1])][:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(lang_samples, 'lang_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_groups = relations.groupby(relations.src_lang).apply(lambda x: x.groupby(x.to_lang).src_word.apply(list))\n",
    "relation_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_samples = {}\n",
    "\n",
    "for _, (src, to, words) in tqdm(relation_groups.reset_index().iterrows()):\n",
    "    relation = '{}{}'.format(src, to)\n",
    "    relation_samples[relation] = np.random.choice(words, min(n_samples, len(words))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(relation_samples, 'relation_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
